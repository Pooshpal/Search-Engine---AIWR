{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>All imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import polars as pl\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Reading data from CSV into a pandas data frame</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"Dataset\\india-news-headlines.csv\", encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Converting the pandas dataframe into a polars dataframe to increase efficiency of compuatations</h2>\n",
    "<font color='grey'>\"Polars supports more parallel operations than Pandas. As Polars is written in Rust, it can run many operations in parallel. Polars supports lazy evaluation. Polars examines your queries, optimizes them, and looks for ways to accelerate the query or reduce memory usage.\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>publish_date</th><th>headline_category</th><th>headline_text</th></tr><tr><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>20010102</td><td>&quot;unknown&quot;</td><td>&quot;Status quo wil...</td></tr><tr><td>20010102</td><td>&quot;unknown&quot;</td><td>&quot;Fissures in Hu...</td></tr><tr><td>20010102</td><td>&quot;unknown&quot;</td><td>&quot;America&#x27;s unwa...</td></tr><tr><td>20010102</td><td>&quot;unknown&quot;</td><td>&quot;For bigwigs; i...</td></tr><tr><td>20010102</td><td>&quot;unknown&quot;</td><td>&quot;Extra buses to...</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌──────────────┬───────────────────┬───────────────────────────────────┐\n",
       "│ publish_date ┆ headline_category ┆ headline_text                     │\n",
       "│ ---          ┆ ---               ┆ ---                               │\n",
       "│ i64          ┆ str               ┆ str                               │\n",
       "╞══════════════╪═══════════════════╪═══════════════════════════════════╡\n",
       "│ 20010102     ┆ unknown           ┆ Status quo will not be disturbed… │\n",
       "│ 20010102     ┆ unknown           ┆ Fissures in Hurriyat over Pak vi… │\n",
       "│ 20010102     ┆ unknown           ┆ America's unwanted heading for I… │\n",
       "│ 20010102     ┆ unknown           ┆ For bigwigs; it is destination G… │\n",
       "│ 20010102     ┆ unknown           ┆ Extra buses to clear tourist tra… │\n",
       "└──────────────┴───────────────────┴───────────────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pl.from_pandas(corpus)\n",
    "display(df.head())\n",
    "#display(df.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pre processing of corpus</h2>\n",
    "<font color='grey'>Tokenizing, removing stop words, stemming or lemmatizing the words, and possibly other techniques like removing punctuation or normalizing capitalization.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('all')\n",
    "\n",
    "# Tokenization\n",
    "corpus['headline_text'] = corpus['headline_text'].apply(nltk.word_tokenize)\n",
    "corpus['headline_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing\n",
    "df['headline_text'] = df['headline_text'].apply(lambda x: [word.lower() for word in x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
